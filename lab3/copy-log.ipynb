{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32836ccc-8cf4-4a5a-998d-8cd6eee35a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd   # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import xgboost as xgb\n",
    "\n",
    "from tune_sklearn import TuneSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import ray\n",
    "\n",
    "# init ray and attach it to local node ray instance\n",
    "ray.init(address='auto')\n",
    "\n",
    "# function to perform the tuning using tune-search library\n",
    "# add function decorator\n",
    "@ray.remote\n",
    "def tune_search_tuning():\n",
    "\n",
    "    # Input data files are available in the \"/var/data/\" directory.\n",
    "    train_df = pd.read_csv(\"train.csv\")\n",
    "    dataset_size = 1000\n",
    "    train_df = train_df.iloc[0:dataset_size, :]\n",
    "    \n",
    "    y = train_df.label.values\n",
    "    x = train_df.drop('label', axis=1).values\n",
    "\n",
    "    # define the train set and test set\n",
    "    # in principle the test (valid) data is not used later, \n",
    "    # so we minimize the size to just 5%.\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.05)\n",
    "    print(\"Shapes - X_train: \", x_train.shape, \", X_val: \", x_val.shape, \", y_train: \", y_train.shape, \", y_val: \", y_val.shape)\n",
    "\n",
    "    # numpy arrays are not accepted in params attributes, \n",
    "    # so we use python comprehension notation to build lists\n",
    "    params = {'max_depth': [3, 6, 10, 15],\n",
    "              'learning_rate': [0.01, 0.1, 0.2, 0.3, 0.4],\n",
    "              'subsample': [0.5 + x / 100 for x in range(10, 50, 10)],\n",
    "              'colsample_bytree': [0.5 + x / 100 for x in range(10, 50, 10)],\n",
    "              'colsample_bylevel': [0.5 + x / 100 for x in range(10, 50, 10)],\n",
    "              'n_estimators': [100, 500, 1000],\n",
    "              'num_class': [10]\n",
    "              }\n",
    "\n",
    "    # define the booster classifier indicating the objective as \n",
    "    # multiclass \"multi:softmax\" and try to speed up execution\n",
    "    # by setting parameter tree_method = \"hist\"\n",
    "    xgbclf = xgb.XGBClassifier(objective=\"multi:softmax\",\n",
    "                               tree_method=\"hist\")\n",
    "\n",
    "    # replace RamdomizedSearchCV by TuneSearchCV\n",
    "    # n_trials sets the number of iterations (different hyperparameter combinations)\n",
    "    # that will be evaluated\n",
    "    # verbosity can be set from 0 to 3 (debug level).\n",
    "    tune_search = TuneSearchCV(estimator=xgbclf,\n",
    "                               param_distributions=params,\n",
    "                               scoring='accuracy',\n",
    "                               n_trials=25,\n",
    "                               verbose=1)\n",
    "\n",
    "    # perform hyperparameter tuning\n",
    "    tune_search.fit(x_train, y_train)\n",
    "\n",
    "    print(\"cv results: \", tune_search.cv_results_)\n",
    "\n",
    "    best_combination = tune_search.best_params_\n",
    "    print(\"Best parameters:\", best_combination)\n",
    "\n",
    "    # evaluate accuracy based on the test dataset\n",
    "\n",
    "    return best_combination\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # create the task\n",
    "    remote_clf = tune_search_tuning.remote()\n",
    "\n",
    "    # get the task result\n",
    "    best_params = ray.get(remote_clf)\n",
    "\n",
    "    stop_time = time.time()\n",
    "    print(\"Stopping at :\", stop_time)\n",
    "    print(\"Total elapsed time: \", stop_time - start_time)\n",
    "\n",
    "    print(\"Best params from main function: \", best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
